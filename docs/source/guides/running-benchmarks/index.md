# Running Benchmarks

Use this section as the mission control for a full benchmark cycle. Every workflow breaks down into the same three steps:

1. **Tune** hyperparameters so each surrogate has a fair starting point.
2. **Train** the selected models with your chosen datasets/studies.
3. **Evaluate** the resulting checkpoints to collect metrics and plots.

```{admonition} TL;DR
Spin through the sub-pages in order if you are new to CODES; drop into a specific step when you just need the CLI flags or folder layout.
```

```{toctree}
:maxdepth: 1

tuning
training
evaluation
```
