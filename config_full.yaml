# Global settings for the benchmark
training_id: "optimizer_test"
surrogates: ["MultiONet", "FullyConnected", "LatentNeuralODE", "LatentPoly"] 
batch_size: [65536, 65536, 512, 512] 
epochs: [200, 200, 110, 200] # [20000, 7500, 20000, 15000]
dataset: 
  name: "cloud"
  log10_transform: True
  log10_transform_params: False
  normalise: "minmax" # "minmax" # "standardise", "minmax", "disable"
  normalise_per_species: True
  use_optimal_params: True
  tolerance: 1e-25
  subset_factor: 1
  log_timesteps: True
devices: ["cuda:0", "cuda:1", "cuda:2", "cuda:3"] # ["cuda:0", "cuda:1", "cuda:2", "cuda:3", "cuda:4", "cuda:5", "cuda:6", "cuda:7", "cuda:8"] 
seed: 42
verbose: False
relative_error_threshold: 1e-10
checkpointing: True

# Models to train
interpolation: 
  enabled: False
  intervals: [2, 3, 4, 5, 6, 7, 8, 9, 10]
extrapolation:
  enabled: False
  cutoffs: [50, 60, 70, 80, 90]
sparse: 
  enabled: False
  factors: [2, 4, 8, 16, 32]
batch_scaling:
  enabled: False
  sizes: [1/16, 1/8, 1/4, 1/2]
uncertainty: 
  enabled: False
  ensemble_size: 5  # Number of models for deep ensemble

# Evaluations during benchmark
losses: True
gradients: True
timing: True
compute: True
compare: True # Whether to compare the surrogates
