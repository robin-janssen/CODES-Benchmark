<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../../img/favicon.ico" />
    <title>Bench Plots - Codes-benchmark</title>
    <link rel="stylesheet" href="../../../../css/theme.css" />
    <link rel="stylesheet" href="../../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Bench Plots";
        var mkdocs_page_input_path = "technical/codes/benchmark/bench_plots.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../../.." class="icon icon-home"> Codes-benchmark
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../../TODO/">Todos for the project</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Technical</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../../../">Codes-benchmark Index</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" >Codes</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" href="../../">Codes</a>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" >Benchmark</a>
    <ul class="current">
                <li class="toctree-l3"><a class="reference internal" href="../">Benchmark</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../bench_fcts/">Bench Fcts</a>
                </li>
                <li class="toctree-l3 current"><a class="reference internal current" href="#">Bench Plots</a>
    <ul class="current">
    <li class="toctree-l4"><a class="reference internal" href="#get_custom_palette">get_custom_palette</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#inference_time_bar_plot">inference_time_bar_plot</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#int_ext_sparse">int_ext_sparse</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_mae_comparison">plot_MAE_comparison</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_mae_comparison_train_duration">plot_MAE_comparison_train_duration</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_average_errors_over_time">plot_average_errors_over_time</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_average_uncertainty_over_time">plot_average_uncertainty_over_time</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_comparative_dynamic_correlation_heatmaps">plot_comparative_dynamic_correlation_heatmaps</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_comparative_error_correlation_heatmaps">plot_comparative_error_correlation_heatmaps</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_dynamic_correlation">plot_dynamic_correlation</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_dynamic_correlation_heatmap">plot_dynamic_correlation_heatmap</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_error_correlation_heatmap">plot_error_correlation_heatmap</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_error_distribution_comparative">plot_error_distribution_comparative</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_error_distribution_per_chemical">plot_error_distribution_per_chemical</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_example_predictions_with_uncertainty">plot_example_predictions_with_uncertainty</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_generalization_error_comparison">plot_generalization_error_comparison</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_generalization_errors">plot_generalization_errors</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_loss_comparison">plot_loss_comparison</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_losses">plot_losses</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_relative_errors">plot_relative_errors</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_relative_errors_over_time">plot_relative_errors_over_time</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_surr_losses">plot_surr_losses</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_uncertainty_over_time_comparison">plot_uncertainty_over_time_comparison</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#plot_uncertainty_vs_errors">plot_uncertainty_vs_errors</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#rel_errors_and_uq">rel_errors_and_uq</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#save_plot">save_plot</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#save_plot_counter">save_plot_counter</a>
    </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../bench_utils/">Bench Utils</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Surrogates</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../surrogates/">Surrogates</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../surrogates/surrogate_classes/">Surrogate Classes</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../surrogates/surrogates/">Surrogates</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Train</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../train/">Train</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../train/train_fcts/">Train Fcts</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Utils</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../utils/">Utils</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../utils/data_utils/">Data Utils</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../utils/utils/">Utils</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Datasets</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" >Data analysis</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../datasets/data_analysis/">Data Analysis</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../../datasets/data_analysis/analyse_dataset/">Analyse Dataset</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../../datasets/data_analysis/data_plots/">Data Plots</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../..">Codes-benchmark</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Technical</li>
          <li class="breadcrumb-item">Codes</li>
          <li class="breadcrumb-item">Benchmark</li>
      <li class="breadcrumb-item active">Bench Plots</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/robin-janssen/CODES-Benchmark/edit/master/docs/technical/codes/benchmark/bench_plots.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="bench-plots">Bench Plots</h1>
<p><a href="../../../#codes-benchmark-index">Codes-benchmark Index</a> / <a href="../../#codes">Codes</a> / <a href="../#benchmark">Benchmark</a> / Bench Plots</p>
<blockquote>
<p>Auto-generated documentation for <a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py">codes.benchmark.bench_plots</a> module.</p>
</blockquote>
<ul>
<li><a href="#bench-plots">Bench Plots</a></li>
<li><a href="#get_custom_palette">get_custom_palette</a></li>
<li><a href="#inference_time_bar_plot">inference_time_bar_plot</a></li>
<li><a href="#int_ext_sparse">int_ext_sparse</a></li>
<li><a href="#plot_mae_comparison">plot_MAE_comparison</a></li>
<li><a href="#plot_mae_comparison_train_duration">plot_MAE_comparison_train_duration</a></li>
<li><a href="#plot_average_errors_over_time">plot_average_errors_over_time</a></li>
<li><a href="#plot_average_uncertainty_over_time">plot_average_uncertainty_over_time</a></li>
<li><a href="#plot_comparative_dynamic_correlation_heatmaps">plot_comparative_dynamic_correlation_heatmaps</a></li>
<li><a href="#plot_comparative_error_correlation_heatmaps">plot_comparative_error_correlation_heatmaps</a></li>
<li><a href="#plot_dynamic_correlation">plot_dynamic_correlation</a></li>
<li><a href="#plot_dynamic_correlation_heatmap">plot_dynamic_correlation_heatmap</a></li>
<li><a href="#plot_error_correlation_heatmap">plot_error_correlation_heatmap</a></li>
<li><a href="#plot_error_distribution_comparative">plot_error_distribution_comparative</a></li>
<li><a href="#plot_error_distribution_per_chemical">plot_error_distribution_per_chemical</a></li>
<li><a href="#plot_example_predictions_with_uncertainty">plot_example_predictions_with_uncertainty</a></li>
<li><a href="#plot_generalization_error_comparison">plot_generalization_error_comparison</a></li>
<li><a href="#plot_generalization_errors">plot_generalization_errors</a></li>
<li><a href="#plot_loss_comparison">plot_loss_comparison</a></li>
<li><a href="#plot_losses">plot_losses</a></li>
<li><a href="#plot_relative_errors">plot_relative_errors</a></li>
<li><a href="#plot_relative_errors_over_time">plot_relative_errors_over_time</a></li>
<li><a href="#plot_surr_losses">plot_surr_losses</a></li>
<li><a href="#plot_uncertainty_over_time_comparison">plot_uncertainty_over_time_comparison</a></li>
<li><a href="#plot_uncertainty_vs_errors">plot_uncertainty_vs_errors</a></li>
<li><a href="#rel_errors_and_uq">rel_errors_and_uq</a></li>
<li><a href="#save_plot">save_plot</a></li>
<li><a href="#save_plot_counter">save_plot_counter</a></li>
</ul>
<h2 id="get_custom_palette">get_custom_palette</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L1645">Show source in bench_plots.py:1645</a></p>
<p>Returns a list of colors sampled from a custom color palette.</p>
<h4 id="arguments">Arguments</h4>
<ul>
<li><code>num_colors</code> <em>int</em> - The number of colors needed.</li>
</ul>
<h4 id="returns">Returns</h4>
<ul>
<li><code>list</code> - A list of RGBA color tuples.</li>
</ul>
<h4 id="signature">Signature</h4>
<pre><code class="language-python">def get_custom_palette(num_colors): ...
</code></pre>
<h2 id="inference_time_bar_plot">inference_time_bar_plot</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L1065">Show source in bench_plots.py:1065</a></p>
<p>Plot the mean inference time with standard deviation for different surrogate models.</p>
<h4 id="arguments_1">Arguments</h4>
<ul>
<li><code>surrogates</code> <em>List[str]</em> - List of surrogate model names.</li>
<li><code>means</code> <em>List[float]</em> - List of mean inference times for each surrogate model.</li>
<li><code>stds</code> <em>List[float]</em> - List of standard deviation of inference times for each surrogate model.</li>
<li><code>config</code> <em>dict</em> - Configuration dictionary.</li>
<li><code>save</code> <em>bool, optional</em> - Whether to save the plot. Defaults to True.</li>
</ul>
<h4 id="returns_1">Returns</h4>
<p>None</p>
<h4 id="signature_1">Signature</h4>
<pre><code class="language-python">def inference_time_bar_plot(
    surrogates: list[str],
    means: list[float],
    stds: list[float],
    config: dict,
    save: bool = True,
) -&gt; None: ...
</code></pre>
<h2 id="int_ext_sparse">int_ext_sparse</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L1691">Show source in bench_plots.py:1691</a></p>
<p>Function to make one comparative plot of the interpolation, extrapolation, and sparse training errors.</p>
<h4 id="arguments_2">Arguments</h4>
<ul>
<li><code>all_metrics</code> <em>dict</em> - dictionary containing the benchmark metrics for each surrogate model.</li>
<li><code>config</code> <em>dict</em> - Configuration dictionary.</li>
</ul>
<h4 id="returns_2">Returns</h4>
<p>None</p>
<h4 id="signature_2">Signature</h4>
<pre><code class="language-python">def int_ext_sparse(all_metrics: dict, config: dict) -&gt; None: ...
</code></pre>
<h2 id="plot_mae_comparison">plot_MAE_comparison</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L873">Show source in bench_plots.py:873</a></p>
<p>Plot the MAE for different surrogate models.</p>
<h4 id="arguments_3">Arguments</h4>
<ul>
<li><code>MAE</code> <em>tuple</em> - Tuple of accuracy arrays for each surrogate model.</li>
<li><code>labels</code> <em>tuple</em> - Tuple of labels for each surrogate model.</li>
<li><code>config</code> <em>dict</em> - Configuration dictionary.</li>
<li><code>save</code> <em>bool</em> - Whether to save the plot.</li>
</ul>
<h4 id="signature_3">Signature</h4>
<pre><code class="language-python">def plot_MAE_comparison(
    MAEs: tuple[np.ndarray, ...],
    labels: tuple[str, ...],
    config: dict,
    save: bool = True,
) -&gt; None: ...
</code></pre>
<h2 id="plot_mae_comparison_train_duration">plot_MAE_comparison_train_duration</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L910">Show source in bench_plots.py:910</a></p>
<p>Plot the MAE for different surrogate models.</p>
<h4 id="arguments_4">Arguments</h4>
<ul>
<li><code>MAE</code> <em>tuple</em> - Tuple of accuracy arrays for each surrogate model.</li>
<li><code>labels</code> <em>tuple</em> - Tuple of labels for each surrogate model.</li>
<li><code>config</code> <em>dict</em> - Configuration dictionary.</li>
<li><code>save</code> <em>bool</em> - Whether to save the plot.</li>
</ul>
<h4 id="signature_4">Signature</h4>
<pre><code class="language-python">def plot_MAE_comparison_train_duration(
    MAEs: tuple[np.ndarray, ...],
    labels: tuple[str, ...],
    train_durations: tuple[float, ...],
    config: dict,
    save: bool = True,
) -&gt; None: ...
</code></pre>
<h2 id="plot_average_errors_over_time">plot_average_errors_over_time</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L258">Show source in bench_plots.py:258</a></p>
<p>Plot the errors over time for different modes (interpolation, extrapolation, sparse, batchsize).</p>
<h4 id="arguments_5">Arguments</h4>
<ul>
<li><code>surr_name</code> <em>str</em> - The name of the surrogate model.</li>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>errors</code> <em>np.ndarray</em> - Errors array of shape [N_metrics, n_timesteps].</li>
<li><code>metrics</code> <em>np.ndarray</em> - Metrics array of shape [N_metrics].</li>
<li><code>timesteps</code> <em>np.ndarray</em> - Timesteps array.</li>
<li><code>mode</code> <em>str</em> - The mode of evaluation ('interpolation', 'extrapolation', 'sparse', 'batchsize').</li>
<li><code>save</code> <em>bool, optional</em> - Whether to save the plot as a file.</li>
</ul>
<h4 id="signature_5">Signature</h4>
<pre><code class="language-python">def plot_average_errors_over_time(
    surr_name: str,
    conf: dict,
    errors: np.ndarray,
    metrics: np.ndarray,
    timesteps: np.ndarray,
    mode: str,
    save: bool = False,
) -&gt; None: ...
</code></pre>
<h2 id="plot_average_uncertainty_over_time">plot_average_uncertainty_over_time</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L455">Show source in bench_plots.py:455</a></p>
<p>Plot the average uncertainty over time.</p>
<h4 id="arguments_6">Arguments</h4>
<ul>
<li><code>surr_name</code> <em>str</em> - The name of the surrogate model.</li>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>errors_time</code> <em>np.ndarray</em> - Prediction errors over time.</li>
<li><code>preds_std</code> <em>np.ndarray</em> - Standard deviation over time of predictions from the ensemble of models.</li>
<li><code>timesteps</code> <em>np.ndarray</em> - Timesteps array.</li>
<li><code>save</code> <em>bool, optional</em> - Whether to save the plot as a file.</li>
</ul>
<h4 id="signature_6">Signature</h4>
<pre><code class="language-python">def plot_average_uncertainty_over_time(
    surr_name: str,
    conf: dict,
    errors_time: np.ndarray,
    preds_std: np.ndarray,
    timesteps: np.ndarray,
    save: bool = False,
) -&gt; None: ...
</code></pre>
<h2 id="plot_comparative_dynamic_correlation_heatmaps">plot_comparative_dynamic_correlation_heatmaps</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L1550">Show source in bench_plots.py:1550</a></p>
<p>Plot comparative heatmaps of correlation between gradient and prediction errors
for multiple surrogate models.</p>
<h4 id="arguments_7">Arguments</h4>
<p>gradients (dict[str, np.ndarray]): Dictionary of gradients from the ensemble of models.
errors (dict[str, np.ndarray]): Dictionary of prediction errors.
avg_correlations (dict[str, float]): Dictionary of average correlations between gradients and prediction errors.
max_grad (dict[str, float]): Dictionary of maximum gradient values for axis scaling across models.
max_err (dict[str, float]): Dictionary of maximum error values for axis scaling across models.
max_count (dict[str, float]): Dictionary of maximum count values for heatmap normalization across models.
- <code>config</code> <em>dict</em> - Configuration dictionary.
- <code>save</code> <em>bool, optional</em> - Whether to save the plot. Defaults to True.</p>
<h4 id="returns_3">Returns</h4>
<p>None</p>
<h4 id="signature_7">Signature</h4>
<pre><code class="language-python">def plot_comparative_dynamic_correlation_heatmaps(
    gradients: dict[str, np.ndarray],
    errors: dict[str, np.ndarray],
    avg_correlations: dict[str, float],
    max_grad: dict[str, float],
    max_err: dict[str, float],
    max_count: dict[str, float],
    config: dict,
    save: bool = True,
) -&gt; None: ...
</code></pre>
<h2 id="plot_comparative_error_correlation_heatmaps">plot_comparative_error_correlation_heatmaps</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L1453">Show source in bench_plots.py:1453</a></p>
<p>Plot comparative heatmaps of correlation between predictive uncertainty and prediction errors
for multiple surrogate models.</p>
<h4 id="arguments_8">Arguments</h4>
<p>preds_std (dict[str, np.ndarray]): Dictionary of standard deviation of predictions from the ensemble of models.
errors (dict[str, np.ndarray]): Dictionary of prediction errors.
avg_correlations (dict[str, float]): Dictionary of average correlations between gradients and prediction errors.
axis_max (dict[str, float]): Dictionary of maximum values for axis scaling across models.
max_count (dict[str, float]): Dictionary of maximum count values for heatmap normalization across models.
- <code>config</code> <em>dict</em> - Configuration dictionary.
- <code>save</code> <em>bool, optional</em> - Whether to save the plot. Defaults to True.</p>
<h4 id="returns_4">Returns</h4>
<p>None</p>
<h4 id="signature_8">Signature</h4>
<pre><code class="language-python">def plot_comparative_error_correlation_heatmaps(
    preds_std: dict[str, np.ndarray],
    errors: dict[str, np.ndarray],
    avg_correlations: dict[str, float],
    axis_max: dict[str, float],
    max_count: dict[str, float],
    config: dict,
    save: bool = True,
) -&gt; None: ...
</code></pre>
<h2 id="plot_dynamic_correlation">plot_dynamic_correlation</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L163">Show source in bench_plots.py:163</a></p>
<p>Plot the correlation between the gradients of the data and the prediction errors.</p>
<h4 id="arguments_9">Arguments</h4>
<ul>
<li><code>surr_name</code> <em>str</em> - The name of the surrogate model.</li>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>gradients</code> <em>np.ndarray</em> - The gradients of the data.</li>
<li><code>errors</code> <em>np.ndarray</em> - The prediction errors.</li>
<li><code>save</code> <em>bool</em> - Whether to save the plot.</li>
</ul>
<h4 id="signature_9">Signature</h4>
<pre><code class="language-python">def plot_dynamic_correlation(
    surr_name: str,
    conf: dict,
    gradients: np.ndarray,
    errors: np.ndarray,
    save: bool = False,
): ...
</code></pre>
<h2 id="plot_dynamic_correlation_heatmap">plot_dynamic_correlation_heatmap</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L1269">Show source in bench_plots.py:1269</a></p>
<p>Plot the correlation between predictive uncertainty and prediction errors using a heatmap.</p>
<h4 id="arguments_10">Arguments</h4>
<ul>
<li><code>surr_name</code> <em>str</em> - The name of the surrogate model.</li>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>preds_std</code> <em>np.ndarray</em> - Standard deviation of predictions from the ensemble of models.</li>
<li><code>errors</code> <em>np.ndarray</em> - Prediction errors.</li>
<li><code>average_correlation</code> <em>float</em> - The average correlation between gradients and prediction errors (pearson correlation).</li>
<li><code>save</code> <em>bool, optional</em> - Whether to save the plot as a file.</li>
<li><code>threshold_factor</code> <em>float, optional</em> - Fraction of max value below which cells are set to 0. Default is 5e-5.</li>
<li><code>cutoff_percent</code> <em>float, optional</em> - The percentage of total counts to include in the heatmap. Default is 0.95.</li>
</ul>
<h4 id="signature_10">Signature</h4>
<pre><code class="language-python">def plot_dynamic_correlation_heatmap(
    surr_name: str,
    conf: dict,
    preds_std: np.ndarray,
    errors: np.ndarray,
    average_correlation: float,
    save: bool = False,
    threshold_factor: float = 0.0001,
    xcut_percent: float = 0.003,
) -&gt; None: ...
</code></pre>
<h2 id="plot_error_correlation_heatmap">plot_error_correlation_heatmap</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L1181">Show source in bench_plots.py:1181</a></p>
<p>Plot the correlation between predictive uncertainty and prediction errors using a heatmap.</p>
<h4 id="arguments_11">Arguments</h4>
<ul>
<li><code>surr_name</code> <em>str</em> - The name of the surrogate model.</li>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>preds_std</code> <em>np.ndarray</em> - Standard deviation of predictions from the ensemble of models.</li>
<li><code>errors</code> <em>np.ndarray</em> - Prediction errors.</li>
<li><code>average_correlation</code> <em>float</em> - The average correlation between gradients and prediction errors (pearson correlation).</li>
<li><code>save</code> <em>bool, optional</em> - Whether to save the plot as a file.</li>
<li><code>threshold_factor</code> <em>float, optional</em> - Fraction of max value below which cells are set to 0. Default is 0.001.</li>
</ul>
<h4 id="signature_11">Signature</h4>
<pre><code class="language-python">def plot_error_correlation_heatmap(
    surr_name: str,
    conf: dict,
    preds_std: np.ndarray,
    errors: np.ndarray,
    average_correlation: float,
    save: bool = False,
    threshold_factor: float = 0.01,
) -&gt; None: ...
</code></pre>
<h2 id="plot_error_distribution_comparative">plot_error_distribution_comparative</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L1354">Show source in bench_plots.py:1354</a></p>
<p>Plot the comparative distribution of errors for each surrogate model as a smoothed histogram plot.</p>
<h4 id="arguments_12">Arguments</h4>
<ul>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>errors</code> <em>dict</em> - Dictionary containing numpy arrays of shape [num_samples, num_timesteps, num_chemicals] for each model.</li>
<li><code>save</code> <em>bool, optional</em> - Whether to save the plot as a file.</li>
</ul>
<h4 id="signature_12">Signature</h4>
<pre><code class="language-python">def plot_error_distribution_comparative(
    errors: dict[str, np.ndarray], conf: dict, save: bool = True
) -&gt; None: ...
</code></pre>
<h2 id="plot_error_distribution_per_chemical">plot_error_distribution_per_chemical</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L655">Show source in bench_plots.py:655</a></p>
<p>Plot the distribution of errors for each chemical as a smoothed histogram plot.</p>
<h4 id="arguments_13">Arguments</h4>
<ul>
<li><code>surr_name</code> <em>str</em> - The name of the surrogate model.</li>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>errors</code> <em>np.ndarray</em> - Errors array of shape [num_samples, num_timesteps, num_chemicals].</li>
<li><code>chemical_names</code> <em>list, optional</em> - List of chemical names for labeling the lines.</li>
<li><code>num_chemicals</code> <em>int, optional</em> - Number of chemicals to plot. Default is 10.</li>
<li><code>save</code> <em>bool, optional</em> - Whether to save the plot as a file.</li>
</ul>
<h4 id="signature_13">Signature</h4>
<pre><code class="language-python">def plot_error_distribution_per_chemical(
    surr_name: str,
    conf: dict,
    errors: np.ndarray,
    chemical_names: list[str] | None = None,
    num_chemicals: int = 10,
    save: bool = True,
) -&gt; None: ...
</code></pre>
<h2 id="plot_example_predictions_with_uncertainty">plot_example_predictions_with_uncertainty</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L331">Show source in bench_plots.py:331</a></p>
<p>Plot example predictions with uncertainty.</p>
<h4 id="arguments_14">Arguments</h4>
<ul>
<li><code>surr_name</code> <em>str</em> - The name of the surrogate model.</li>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>preds_mean</code> <em>np.ndarray</em> - Mean predictions from the ensemble of models.</li>
<li><code>preds_std</code> <em>np.ndarray</em> - Standard deviation of predictions from the ensemble of models.</li>
<li><code>targets</code> <em>np.ndarray</em> - True targets.</li>
<li><code>timesteps</code> <em>np.ndarray</em> - Timesteps array.</li>
<li><code>example_idx</code> <em>int, optional</em> - Index of the example to plot. Default is 0.</li>
<li><code>num_chemicals</code> <em>int, optional</em> - Number of chemicals to plot. Default is 100.</li>
<li><code>labels</code> <em>list, optional</em> - List of labels for the chemicals.</li>
<li><code>save</code> <em>bool, optional</em> - Whether to save the plot as a file.</li>
</ul>
<h4 id="signature_14">Signature</h4>
<pre><code class="language-python">def plot_example_predictions_with_uncertainty(
    surr_name: str,
    conf: dict,
    preds_mean: np.ndarray,
    preds_std: np.ndarray,
    targets: np.ndarray,
    timesteps: np.ndarray,
    example_idx: int = 0,
    num_chemicals: int = 100,
    labels: list[str] | None = None,
    save: bool = False,
) -&gt; None: ...
</code></pre>
<h2 id="plot_generalization_error_comparison">plot_generalization_error_comparison</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L1123">Show source in bench_plots.py:1123</a></p>
<p>Plot the generalization errors of different surrogate models.</p>
<h4 id="arguments_15">Arguments</h4>
<ul>
<li><code>surrogates</code> <em>list</em> - List of surrogate model names.</li>
<li><code>metrics_list</code> <em>list[np.array]</em> - List of numpy arrays containing the metrics for each surrogate model.</li>
<li><code>model_errors_list</code> <em>list[np.array]</em> - List of numpy arrays containing the errors for each surrogate model.</li>
<li><code>xlabel</code> <em>str</em> - Label for the x-axis.</li>
<li><code>filename</code> <em>str</em> - Filename to save the plot.</li>
<li><code>config</code> <em>dict</em> - Configuration dictionary.</li>
<li><code>save</code> <em>bool</em> - Whether to save the plot.</li>
<li><code>xlog</code> <em>bool</em> - Whether to use a log scale for the x-axis.</li>
</ul>
<h4 id="returns_5">Returns</h4>
<p>None</p>
<h4 id="signature_15">Signature</h4>
<pre><code class="language-python">def plot_generalization_error_comparison(
    surrogates: list[str],
    metrics_list: list[np.array],
    model_errors_list: list[np.array],
    xlabel: str,
    filename: str,
    config: dict,
    save: bool = True,
    xlog: bool = False,
) -&gt; None: ...
</code></pre>
<h2 id="plot_generalization_errors">plot_generalization_errors</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L198">Show source in bench_plots.py:198</a></p>
<p>Plot the generalization errors of a model for various metrics.</p>
<h4 id="arguments_16">Arguments</h4>
<ul>
<li><code>surr_name</code> <em>str</em> - The name of the surrogate model.</li>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>metrics</code> <em>np.ndarray</em> - The metrics (e.g., intervals, cutoffs, batch sizes, number of training samples).</li>
<li><code>model_errors</code> <em>np.ndarray</em> - The model errors.</li>
<li><code>mode</code> <em>str</em> - The mode of generalization ("interpolation", "extrapolation", "sparse", "batchsize").</li>
<li><code>save</code> <em>bool</em> - Whether to save the plot.</li>
</ul>
<h4 id="returns_6">Returns</h4>
<p>None</p>
<h4 id="signature_16">Signature</h4>
<pre><code class="language-python">def plot_generalization_errors(
    surr_name: str,
    conf: dict,
    metrics: np.ndarray,
    model_errors: np.ndarray,
    mode: str,
    save: bool = False,
) -&gt; None: ...
</code></pre>
<h2 id="plot_loss_comparison">plot_loss_comparison</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L828">Show source in bench_plots.py:828</a></p>
<p>Plot the training and test losses for different surrogate models.</p>
<h4 id="arguments_17">Arguments</h4>
<ul>
<li><code>train_losses</code> <em>tuple</em> - Tuple of training loss arrays for each surrogate model.</li>
<li><code>test_losses</code> <em>tuple</em> - Tuple of test loss arrays for each surrogate model.</li>
<li><code>labels</code> <em>tuple</em> - Tuple of labels for each surrogate model.</li>
<li><code>config</code> <em>dict</em> - Configuration dictionary.</li>
<li><code>save</code> <em>bool</em> - Whether to save the plot.</li>
</ul>
<h4 id="returns_7">Returns</h4>
<p>None</p>
<h4 id="signature_17">Signature</h4>
<pre><code class="language-python">def plot_loss_comparison(
    train_losses: tuple[np.ndarray, ...],
    test_losses: tuple[np.ndarray, ...],
    labels: tuple[str, ...],
    config: dict,
    save: bool = True,
) -&gt; None: ...
</code></pre>
<h2 id="plot_losses">plot_losses</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L775">Show source in bench_plots.py:775</a></p>
<p>Plot the loss trajectories for the training of multiple models.</p>
<h4 id="arguments_18">Arguments</h4>
<ul>
<li><code>loss_histories</code> - List of loss history arrays.</li>
<li><code>labels</code> - List of labels for each loss history.</li>
<li><code>title</code> - Title of the plot.</li>
<li><code>save</code> - Whether to save the plot as an image file.</li>
<li><code>conf</code> - The configuration dictionary.</li>
<li><code>surr_name</code> - The name of the surrogate model.</li>
<li><code>mode</code> - The mode of the training.</li>
</ul>
<h4 id="signature_18">Signature</h4>
<pre><code class="language-python">def plot_losses(
    loss_histories: tuple[np.array, ...],
    labels: tuple[str, ...],
    title: str = &quot;Losses&quot;,
    save: bool = False,
    conf: Optional[dict] = None,
    surr_name: Optional[str] = None,
    mode: str = &quot;main&quot;,
) -&gt; None: ...
</code></pre>
<h2 id="plot_relative_errors">plot_relative_errors</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L949">Show source in bench_plots.py:949</a></p>
<p>Plot the relative errors over time for different surrogate models.</p>
<h4 id="arguments_19">Arguments</h4>
<ul>
<li><code>mean_errors</code> <em>dict</em> - dictionary containing the mean relative errors for each surrogate model.</li>
<li><code>median_errors</code> <em>dict</em> - dictionary containing the median relative errors for each surrogate model.</li>
<li><code>timesteps</code> <em>np.ndarray</em> - Array of timesteps.</li>
<li><code>config</code> <em>dict</em> - Configuration dictionary.</li>
<li><code>save</code> <em>bool</em> - Whether to save the plot.</li>
</ul>
<h4 id="returns_8">Returns</h4>
<p>None</p>
<h4 id="signature_19">Signature</h4>
<pre><code class="language-python">def plot_relative_errors(
    mean_errors: dict[str, np.ndarray],
    median_errors: dict[str, np.ndarray],
    timesteps: np.ndarray,
    config: dict,
    save: bool = True,
) -&gt; None: ...
</code></pre>
<h2 id="plot_relative_errors_over_time">plot_relative_errors_over_time</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L86">Show source in bench_plots.py:86</a></p>
<p>Plot the mean and median relative errors over time with shaded regions for
the 50th, 90th, and 99th percentiles.</p>
<h4 id="arguments_20">Arguments</h4>
<ul>
<li><code>surr_name</code> <em>str</em> - The name of the surrogate model.</li>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>relative_errors</code> <em>np.ndarray</em> - The relative errors of the model.</li>
<li><code>title</code> <em>str</em> - The title of the plot.</li>
<li><code>save</code> <em>bool</em> - Whether to save the plot.</li>
</ul>
<h4 id="signature_20">Signature</h4>
<pre><code class="language-python">def plot_relative_errors_over_time(
    surr_name: str,
    conf: dict,
    relative_errors: np.ndarray,
    title: str,
    save: bool = False,
) -&gt; None: ...
</code></pre>
<h2 id="plot_surr_losses">plot_surr_losses</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L525">Show source in bench_plots.py:525</a></p>
<p>Plot the training and test losses for the surrogate model.</p>
<h4 id="arguments_21">Arguments</h4>
<ul>
<li><code>model</code> - Instance of the surrogate model class.</li>
<li><code>surr_name</code> <em>str</em> - The name of the surrogate model.</li>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>timesteps</code> <em>np.ndarray</em> - The timesteps array.</li>
</ul>
<h4 id="signature_21">Signature</h4>
<pre><code class="language-python">def plot_surr_losses(
    model, surr_name: str, conf: dict, timesteps: np.ndarray
) -&gt; None: ...
</code></pre>
<h2 id="plot_uncertainty_over_time_comparison">plot_uncertainty_over_time_comparison</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L1007">Show source in bench_plots.py:1007</a></p>
<p>Plot the uncertainty over time for different surrogate models.</p>
<h4 id="arguments_22">Arguments</h4>
<ul>
<li><code>uncertainties</code> <em>dict</em> - Dictionary containing the uncertainties for each surrogate model.</li>
<li><code>absolute_errors</code> <em>dict</em> - Dictionary containing the absolute errors for each surrogate model.</li>
<li><code>timesteps</code> <em>np.ndarray</em> - Array of timesteps.</li>
<li><code>config</code> <em>dict</em> - Configuration dictionary.</li>
<li><code>save</code> <em>bool</em> - Whether to save the plot.</li>
</ul>
<h4 id="returns_9">Returns</h4>
<p>None</p>
<h4 id="signature_22">Signature</h4>
<pre><code class="language-python">def plot_uncertainty_over_time_comparison(
    uncertainties: dict[str, np.ndarray],
    absolute_errors: dict[str, np.ndarray],
    timesteps: np.ndarray,
    config: dict,
    save: bool = True,
) -&gt; None: ...
</code></pre>
<h2 id="plot_uncertainty_vs_errors">plot_uncertainty_vs_errors</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L493">Show source in bench_plots.py:493</a></p>
<p>Plot the correlation between predictive uncertainty and prediction errors.</p>
<h4 id="arguments_23">Arguments</h4>
<ul>
<li><code>surr_name</code> <em>str</em> - The name of the surrogate model.</li>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>preds_std</code> <em>np.ndarray</em> - Standard deviation of predictions from the ensemble of models.</li>
<li><code>errors</code> <em>np.ndarray</em> - Prediction errors.</li>
<li><code>save</code> <em>bool, optional</em> - Whether to save the plot as a file.</li>
</ul>
<h4 id="signature_23">Signature</h4>
<pre><code class="language-python">def plot_uncertainty_vs_errors(
    surr_name: str,
    conf: dict,
    preds_std: np.ndarray,
    errors: np.ndarray,
    save: bool = False,
) -&gt; None: ...
</code></pre>
<h2 id="rel_errors_and_uq">rel_errors_and_uq</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L1830">Show source in bench_plots.py:1830</a></p>
<p>Create a figure with two subplots: relative errors over time and uncertainty over time for different surrogate models.</p>
<h4 id="arguments_24">Arguments</h4>
<ul>
<li><code>metrics</code> <em>dict</em> - Dictionary containing the benchmark metrics for each surrogate model.</li>
<li><code>config</code> <em>dict</em> - Configuration dictionary.</li>
<li><code>save</code> <em>bool</em> - Whether to save the plot.</li>
</ul>
<h4 id="returns_10">Returns</h4>
<p>None</p>
<h4 id="signature_24">Signature</h4>
<pre><code class="language-python">def rel_errors_and_uq(
    metrics: dict[str, dict], config: dict, save: bool = True
) -&gt; None: ...
</code></pre>
<h2 id="save_plot">save_plot</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L15">Show source in bench_plots.py:15</a></p>
<p>Save the plot to a file, creating necessary directories if they don't exist.</p>
<h4 id="arguments_25">Arguments</h4>
<ul>
<li><code>plt</code> <em>matplotlib.pyplot</em> - The plot object to save.</li>
<li><code>filename</code> <em>str</em> - The desired filename for the plot.</li>
<li><code>conf</code> <em>dict</em> - The configuration dictionary.</li>
<li><code>surr_name</code> <em>str</em> - The name of the surrogate model.</li>
<li><code>dpi</code> <em>int</em> - The resolution of the saved plot.</li>
<li><code>base_dir</code> <em>str, optional</em> - The base directory where plots will be saved. Default is "plots".</li>
<li><code>increase_count</code> <em>bool, optional</em> - Whether to increment the filename count if a file already exists. Default is True.</li>
</ul>
<h4 id="raises">Raises</h4>
<ul>
<li><code>ValueError</code> - If the configuration dictionary does not contain the required keys.</li>
</ul>
<h4 id="signature_25">Signature</h4>
<pre><code class="language-python">def save_plot(
    plt,
    filename: str,
    conf: dict,
    surr_name: str = &quot;&quot;,
    dpi: int = 300,
    base_dir: str = &quot;plots&quot;,
    increase_count: bool = False,
) -&gt; None: ...
</code></pre>
<h2 id="save_plot_counter">save_plot_counter</h2>
<p><a href="https://github.com/robin-janssen/CODES-Benchmark/blob/main/codes/benchmark/bench_plots.py#L54">Show source in bench_plots.py:54</a></p>
<p>Save a plot with an incremented filename if a file with the same name already exists.</p>
<h4 id="arguments_26">Arguments</h4>
<ul>
<li><code>filename</code> <em>str</em> - The desired filename for the plot.</li>
<li><code>directory</code> <em>str</em> - The directory to save the plot in.</li>
<li><code>increase_count</code> <em>bool, optional</em> - Whether to increment the filename count if a file already exists. Default is True.</li>
</ul>
<h4 id="returns_11">Returns</h4>
<ul>
<li><code>str</code> - The full path to the saved plot.</li>
</ul>
<h4 id="signature_26">Signature</h4>
<pre><code class="language-python">def save_plot_counter(
    filename: str, directory: str, increase_count: bool = True
) -&gt; str: ...
</code></pre>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../bench_fcts/" class="btn btn-neutral float-left" title="Bench Fcts"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../bench_utils/" class="btn btn-neutral float-right" title="Bench Utils">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/robin-janssen/CODES-Benchmark" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../bench_fcts/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../bench_utils/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../../..";</script>
    <script src="../../../../js/theme_extra.js"></script>
    <script src="../../../../js/theme.js"></script>
      <script src="../../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
